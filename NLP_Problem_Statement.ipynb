{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Astuto NLP Problem Statement.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzOn2XH6jqns"
      },
      "source": [
        "# Astuto NLP Problem Statement:\n",
        "## Business Context\n",
        "We are building a Customer Experience platform for B2B Customers. One of the core component of this Customer Experience Platform is our NLP Engine, which would consume textual data and generate insights.\n",
        "## Problem statement:\n",
        "We have recently started working building an initial iteration for an Ecommerce customer with their Reviews data.\n",
        "Let us use a dataset available in Kaggle for our reference. Link to ecommerce reviews data\n",
        "https://www.kaggle.com/datafiniti/consumer-reviews-of-amazon-products?select=Datafiniti_Amazon_Consumer_Reviews_of_Amazon_Products.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Olt7GSPzjj-s"
      },
      "source": [
        "## Problem formulation and assumptions\n",
        "We need to extract meaningful insights from user reviews in this project. User reviews generally contain useful aspects of the product usage. Fetching these aspects as keywords / keyphrase will be valuable addition.\n",
        "\n",
        "There are numerous studies in the area of keyphrase extraction. They can majorly be categorized into 4 approaches\n",
        "\n",
        "1.   Co-occurrence based\n",
        "2.   Graph based\n",
        "3.   Deep Extractive models\n",
        "4.   Deep Generative models\n",
        "\n",
        "There are a few off-the-shelf libraries available for Co-occurrence and Extractive approaches. We will try some of them to get an understanding of their capabilities.\n",
        "\n",
        "\n",
        "**Assumptions**\n",
        "*   Feedback from business team is that previous approach was 'very generic', this generally signify initial approach has high recall. We should strive to come up with approach with high precision.\n",
        "*   Extracting 'meaningful labels': Adding context to extracted keywords will be beneficial. One way to achieve this is to increase the context window.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFGBpEl0Q3FX"
      },
      "source": [
        "## Accessing Data\n",
        "I have put the data in my drive, will fetch and unzip it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVBeamqfjdL_",
        "outputId": "0ab3bafa-0eb1-4408-87f5-ac4585626d50"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPNsGmAFDrE0",
        "outputId": "84b25917-9736-446a-d633-b3b81541bc53"
      },
      "source": [
        "!unzip /content/drive/MyDrive/LeadSquared_Assignment/Datafiniti_Amazon_Consumer_Reviews_of_Amazon_Products.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/MyDrive/LeadSquared_Assignment/Datafiniti_Amazon_Consumer_Reviews_of_Amazon_Products.zip\n",
            "  inflating: Datafiniti_Amazon_Consumer_Reviews_of_Amazon_Products.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85xYRqeiREdg"
      },
      "source": [
        "## Importing libraries\n",
        "Here, we import few required libraries. For other libraries, we will install and import them as and when required instead of importing in the begining. This requires less resource in Colab environment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1l-mts6v0Wd"
      },
      "source": [
        "import nltk\n",
        "import pandas as pd\n",
        "from typing import *"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxVJqKXOBFNX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f55c1b91-ed3e-4e2c-97aa-434b7f90d47d"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "stopwords = nltk.corpus.stopwords.words('english')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TPELT4ZB66U"
      },
      "source": [
        "## Read data\n",
        "Reading the data as a dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "ngj2md4WBH3X",
        "outputId": "9f175103-88ff-4487-8e12-200ca49b58f4"
      },
      "source": [
        "products_df = pd.read_csv('Datafiniti_Amazon_Consumer_Reviews_of_Amazon_Products.csv')\n",
        "products_df.tail(2)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>dateAdded</th>\n",
              "      <th>dateUpdated</th>\n",
              "      <th>name</th>\n",
              "      <th>asins</th>\n",
              "      <th>brand</th>\n",
              "      <th>categories</th>\n",
              "      <th>primaryCategories</th>\n",
              "      <th>imageURLs</th>\n",
              "      <th>keys</th>\n",
              "      <th>manufacturer</th>\n",
              "      <th>manufacturerNumber</th>\n",
              "      <th>reviews.date</th>\n",
              "      <th>reviews.dateAdded</th>\n",
              "      <th>reviews.dateSeen</th>\n",
              "      <th>reviews.doRecommend</th>\n",
              "      <th>reviews.id</th>\n",
              "      <th>reviews.numHelpful</th>\n",
              "      <th>reviews.rating</th>\n",
              "      <th>reviews.sourceURLs</th>\n",
              "      <th>reviews.text</th>\n",
              "      <th>reviews.title</th>\n",
              "      <th>reviews.username</th>\n",
              "      <th>sourceURLs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4998</th>\n",
              "      <td>AVqkIdZiv8e3D1O-leaJ</td>\n",
              "      <td>2017-03-06T14:59:25Z</td>\n",
              "      <td>2017-09-04T11:19:31Z</td>\n",
              "      <td>Fire Tablet with Alexa, 7\" Display, 16 GB, Mag...</td>\n",
              "      <td>B018Y224PY</td>\n",
              "      <td>Amazon</td>\n",
              "      <td>Tablets,Fire Tablets,Electronics,iPad &amp; Tablet...</td>\n",
              "      <td>Electronics</td>\n",
              "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
              "      <td>841667103150,0841667103150,firetabletwithalexa...</td>\n",
              "      <td>Amazon</td>\n",
              "      <td>B018Y224PY</td>\n",
              "      <td>2016-09-02T00:00:00.000Z</td>\n",
              "      <td>2017-05-22T21:44:38Z</td>\n",
              "      <td>2017-04-30T02:06:56.574Z,2017-06-07T08:20:53.942Z</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>http://reviews.bestbuy.com/3545/5025900/review...</td>\n",
              "      <td>I had some thoughts about getting this for a 5...</td>\n",
              "      <td>Very sturdy for a 5 year old</td>\n",
              "      <td>Mrbilly</td>\n",
              "      <td>https://www.barcodable.com/upc/841667103150,ht...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4999</th>\n",
              "      <td>AVqkIdZiv8e3D1O-leaJ</td>\n",
              "      <td>2017-03-06T14:59:25Z</td>\n",
              "      <td>2017-09-04T11:19:31Z</td>\n",
              "      <td>Fire Tablet with Alexa, 7\" Display, 16 GB, Mag...</td>\n",
              "      <td>B018Y224PY</td>\n",
              "      <td>Amazon</td>\n",
              "      <td>Tablets,Fire Tablets,Electronics,iPad &amp; Tablet...</td>\n",
              "      <td>Electronics</td>\n",
              "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
              "      <td>841667103150,0841667103150,firetabletwithalexa...</td>\n",
              "      <td>Amazon</td>\n",
              "      <td>B018Y224PY</td>\n",
              "      <td>2016-05-19T00:00:00.000Z</td>\n",
              "      <td>2017-04-04T09:55:17Z</td>\n",
              "      <td>2017-04-03T03:55:09.054Z,2017-04-30T02:03:18.1...</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>http://reviews.bestbuy.com/3545/5025900/review...</td>\n",
              "      <td>this is a steal, have 8 gb model as well.This ...</td>\n",
              "      <td>great little tablet</td>\n",
              "      <td>tabman</td>\n",
              "      <td>https://www.barcodable.com/upc/841667103150,ht...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        id  ...                                         sourceURLs\n",
              "4998  AVqkIdZiv8e3D1O-leaJ  ...  https://www.barcodable.com/upc/841667103150,ht...\n",
              "4999  AVqkIdZiv8e3D1O-leaJ  ...  https://www.barcodable.com/upc/841667103150,ht...\n",
              "\n",
              "[2 rows x 24 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSL2hDpnB_kZ"
      },
      "source": [
        "#### Analysing Input Text\n",
        "We observe that there are many columns which are not required for our purposes. We will remove those and only keep the required ones. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "w5C0VwrmWj4C",
        "outputId": "f3940a7a-8dda-4c87-fea8-4db839ba5f8d"
      },
      "source": [
        "products_df = products_df[['id', 'reviews.text', 'reviews.rating', 'reviews.title', 'primaryCategories', 'name']].copy()\n",
        "products_df.rename(columns={'reviews.text': 'review', 'reviews.rating': 'rating', 'reviews.title': 'title', 'primaryCategories': 'category'}, inplace=True)\n",
        "products_df.head(2)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>review</th>\n",
              "      <th>rating</th>\n",
              "      <th>title</th>\n",
              "      <th>category</th>\n",
              "      <th>name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AVqVGZNvQMlgsOJE6eUY</td>\n",
              "      <td>I thought it would be as big as small paper bu...</td>\n",
              "      <td>3</td>\n",
              "      <td>Too small</td>\n",
              "      <td>Electronics</td>\n",
              "      <td>Amazon Kindle E-Reader 6\" Wifi (8th Generation...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AVqVGZNvQMlgsOJE6eUY</td>\n",
              "      <td>This kindle is light and easy to use especiall...</td>\n",
              "      <td>5</td>\n",
              "      <td>Great light reader. Easy to use at the beach</td>\n",
              "      <td>Electronics</td>\n",
              "      <td>Amazon Kindle E-Reader 6\" Wifi (8th Generation...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     id  ...                                               name\n",
              "0  AVqVGZNvQMlgsOJE6eUY  ...  Amazon Kindle E-Reader 6\" Wifi (8th Generation...\n",
              "1  AVqVGZNvQMlgsOJE6eUY  ...  Amazon Kindle E-Reader 6\" Wifi (8th Generation...\n",
              "\n",
              "[2 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QjbSh1pX8ZU",
        "outputId": "01c35717-fd7d-4ca8-aa91-0015478d9ae6"
      },
      "source": [
        "products_df.category.value_counts()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Electronics                    3276\n",
              "Electronics,Hardware           1435\n",
              "Office Supplies,Electronics     265\n",
              "Electronics,Media                24\n",
              "Name: category, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0KP2GJpSBkP"
      },
      "source": [
        "As we see, majority of the reviews are coming for 'Electronics' category. Different category might different approach, for example, electronic items can have aspect 'battery life' whereas books has no such aspect. However, our approach here will not vary based on category.\n",
        "\n",
        "Lets deduplicate our data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PbJ5nHARbN4",
        "outputId": "60978c4c-4841-4766-ced8-58111a00a831"
      },
      "source": [
        "## Remove rows if review text is duplicate:\n",
        "print(f'Reviews remaining before deduplication: [{products_df.shape[0]}]')\n",
        "products_df.drop_duplicates(subset=['review'])\n",
        "print(f'Reviews remaining after deduplication: [{products_df.shape[0]}]')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reviews remaining before deduplication: [5000]\n",
            "Reviews remaining after deduplication: [5000]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHVV97A_S3bK"
      },
      "source": [
        "We will get the tokens from the reviews to get various token frequency based statistics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "wGAdkguvJh-a",
        "outputId": "53eeaa21-6aae-40ea-ad39-8a66817492f0"
      },
      "source": [
        "products_df['review_tokens'] = products_df['review'].str.lower().str.split()\n",
        "products_df['token_count'] = products_df['review'].str.lower().str.split().str.len()\n",
        "products_df.head(2)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>review</th>\n",
              "      <th>rating</th>\n",
              "      <th>title</th>\n",
              "      <th>category</th>\n",
              "      <th>name</th>\n",
              "      <th>review_tokens</th>\n",
              "      <th>token_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AVqVGZNvQMlgsOJE6eUY</td>\n",
              "      <td>I thought it would be as big as small paper bu...</td>\n",
              "      <td>3</td>\n",
              "      <td>Too small</td>\n",
              "      <td>Electronics</td>\n",
              "      <td>Amazon Kindle E-Reader 6\" Wifi (8th Generation...</td>\n",
              "      <td>[i, thought, it, would, be, as, big, as, small...</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AVqVGZNvQMlgsOJE6eUY</td>\n",
              "      <td>This kindle is light and easy to use especiall...</td>\n",
              "      <td>5</td>\n",
              "      <td>Great light reader. Easy to use at the beach</td>\n",
              "      <td>Electronics</td>\n",
              "      <td>Amazon Kindle E-Reader 6\" Wifi (8th Generation...</td>\n",
              "      <td>[this, kindle, is, light, and, easy, to, use, ...</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     id  ... token_count\n",
              "0  AVqVGZNvQMlgsOJE6eUY  ...          41\n",
              "1  AVqVGZNvQMlgsOJE6eUY  ...          12\n",
              "\n",
              "[2 rows x 8 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXvXJWQ3TDfc"
      },
      "source": [
        "One important point to note here is that a single product can have multiple reviews. We need to aggregate KeyPhrase extraction over all the reviews for a single product.\n",
        "\n",
        "Let us see how many unique products are present in the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPSFw41pKPJX",
        "outputId": "4b37e577-0e93-4991-ace9-2cfb8bcc0b17"
      },
      "source": [
        "unique_products = products_df.id.value_counts()\n",
        "unique_products"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AVqkIhwDv8e3D1O-lebb    797\n",
              "AWFUWc8THh53nbDRF6YO    650\n",
              "AWMjT0WguC1rwyj_rFh3    590\n",
              "AVph0EeEilAPnD_x9myq    561\n",
              "AVpjEN4jLJeJML43rpUe    467\n",
              "AVpgdkC8ilAPnD_xsvyi    371\n",
              "AVpfpK8KLJeJML43BCuD    225\n",
              "AVqVGWLKnnc1JgDc3jF1    217\n",
              "AWK8z0pOIwln0LfXlSxH    195\n",
              "AVqVGZSEQMlgsOJE6eUc    159\n",
              "AVpidLjVilAPnD_xEVpI    106\n",
              "AVqkIdZiv8e3D1O-leaJ    101\n",
              "AVqVGZNvQMlgsOJE6eUY     96\n",
              "AVphPmHuilAPnD_x3E5h     82\n",
              "AVqkIh9HQMlgsOJE6fu_     70\n",
              "AVqkIh8WQMlgsOJE6fu-     58\n",
              "AVqkIj9snnc1JgDc3khU     53\n",
              "AVqkIhkhv8e3D1O-lebZ     51\n",
              "AVqkIiKWnnc1JgDc3khH     40\n",
              "AVqVGZN9QMlgsOJE6eUZ     39\n",
              "AVqVGZO3nnc1JgDc3jGK     24\n",
              "AVpfIfGA1cnluZ0-emyp     22\n",
              "AVpftoij1cnluZ0-p5n2     22\n",
              "AV-XeQLWuC1rwyj_gbP5      4\n",
              "Name: id, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPfjpFpFLQ7m",
        "outputId": "e0c3c415-aa91-4a72-f3ac-b297cd725a0f"
      },
      "source": [
        "print(f'There are total [{len(unique_products)}] products.')\n",
        "print(f'Product [{products_df.loc[products_df[\"id\"] == unique_products.index[0]][\"name\"].iloc[0]}] has most reviews [{unique_products.iloc[0]}].')\n",
        "print(f'Product [{products_df.loc[products_df[\"id\"] == unique_products.index[-1]][\"name\"].iloc[0]}] has least reviews [{unique_products.iloc[-1]}].')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are total [24] products.\n",
            "Product [All-New Fire HD 8 Tablet, 8\" HD Display, Wi-Fi, 16 GB - Includes Special Offers, Magenta] has most reviews [797].\n",
            "Product [Amazon Fire TV with 4K Ultra HD and Alexa Voice Remote (Pendant Design) | Streaming Media Player] has least reviews [4].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FpmboY0Tew2"
      },
      "source": [
        "Filter out the product id with the least number of reviews for faster testing and evaluation purposes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3QsZj6Tqvvn"
      },
      "source": [
        "product_least_review = unique_products.index[-1]"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0w7Be_IuLW-4"
      },
      "source": [
        "from collections import Counter, OrderedDict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05bOeevBMZvE"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yk1kmkFhLHHv"
      },
      "source": [
        "token_freqs = Counter(tokens_unique)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0EzMM_gTwGS"
      },
      "source": [
        "Lets us see the token frequencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNxU1OiXTwiW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "outputId": "2b6e298d-5c43-4db1-fd67-68d82fbfbefd"
      },
      "source": [
        "n = 20\n",
        "top_n_tokens_odict = OrderedDict(token_freqs.most_common(n))\n",
        "bottom_n_tokens_odict = OrderedDict(token_freqs.most_common()[:-n-1:-1])\n",
        "\n",
        "plt.bar(top_n_tokens_odict.keys(), top_n_tokens_odict.values())\n",
        "plt.show()"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYCjDx4hT0RY"
      },
      "source": [
        "As expected, majority of the high frequency words are stopwords.\n",
        "Let us remove stopwords and clean up a little."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDILRHyxTH-u"
      },
      "source": [
        "import unicodedata, re"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kj0myjMJGcOE"
      },
      "source": [
        "wnl = nltk.stem.WordNetLemmatizer()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8s-xt88CFpsv"
      },
      "source": [
        "def get_clean_text(txt:str, stopwords:list=stopwords, return_tokens:bool=False) -> Union[List, str]:\n",
        "    \"\"\" Cleans a str by normalizing, lowercasing and removing stopwords \"\"\"\n",
        "    txt = (unicodedata.normalize('NFKD', txt).encode('ascii', 'ignore').decode('utf-8', 'ignore').lower())\n",
        "    words = re.sub(r'[^\\w\\s]', '', txt).split()\n",
        "\n",
        "    clean_txt = [wnl.lemmatize(word) for word in words if word not in stopwords]\n",
        "\n",
        "    if return_tokens:\n",
        "        return clean_txt\n",
        "    else:\n",
        "        return ' '.join(clean_txt)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "id": "8Hb8KZniZ5y1",
        "outputId": "bcf8c7dd-cd40-4661-a244-210872c87af8"
      },
      "source": [
        "sanity_text = 'hello there, sam'\n",
        "get_clean_text(sanity_text, return_tokens=True)\n",
        "\n",
        "assert get_clean_text(sanity_text) == 'hello sam'\n",
        "assert get_clean_text(sanity_text, return_tokens=True) == ['hello', 'sam']"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-9e7f3ce9e610>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msanity_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'hello there, sam'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mget_clean_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanity_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mget_clean_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanity_text\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'hello sam'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mget_clean_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanity_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'hello'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sam'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'get_clean_text' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGYjg_7ubEfx"
      },
      "source": [
        "from functools import partial\n",
        "get_clean_text_tokens = partial(get_clean_text, return_tokens=True)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VG_h8euSuo5",
        "outputId": "7e346b62-5996-4f7a-efeb-9df77c7f4f12"
      },
      "source": [
        "products_df['review_tokens_cleaned'] = products_df['review'].apply(get_clean_text_tokens)\n",
        "products_df['review_tokens_cleaned']"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       [thought, would, big, small, paper, turn, like...\n",
              "1           [kindle, light, easy, use, especially, beach]\n",
              "2       [didnt, know, much, id, use, kindle, went, low...\n",
              "3       [100, happy, purchase, caught, sale, really, g...\n",
              "4       [solid, entry, level, kindle, great, kid, gift...\n",
              "                              ...                        \n",
              "4995            [great, tablet, price, amazon, good, job]\n",
              "4996    [tablet, perfect, size, easy, use, read, play,...\n",
              "4997    [purchased, son, room, upgrade, memory, allow,...\n",
              "4998    [thought, getting, 5, year, old, get, screen, ...\n",
              "4999               [steal, 8, gb, model, wellthis, punch]\n",
              "Name: review_tokens_cleaned, Length: 5000, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qPDkimxbMN2",
        "outputId": "e5ca6ee5-938e-4718-ac5e-94a60b90e941"
      },
      "source": [
        "products_df['review_cleaned'] = products_df['review'].apply(get_clean_text)\n",
        "products_df['review_cleaned']"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       thought would big small paper turn like palm t...\n",
              "1                  kindle light easy use especially beach\n",
              "2       didnt know much id use kindle went lower end i...\n",
              "3       100 happy purchase caught sale really good pri...\n",
              "4       solid entry level kindle great kid gifted kid ...\n",
              "                              ...                        \n",
              "4995                   great tablet price amazon good job\n",
              "4996    tablet perfect size easy use read play game pu...\n",
              "4997    purchased son room upgrade memory allow book g...\n",
              "4998    thought getting 5 year old get screen protecto...\n",
              "4999                      steal 8 gb model wellthis punch\n",
              "Name: review_cleaned, Length: 5000, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RrpPF7VqB-d"
      },
      "source": [
        "We need to generate keywords per product by aggregating over all reviews."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Gu2zniHlVek"
      },
      "source": [
        "product_dfs = {}\n",
        "products_keywords = {}\n",
        "for product_id, product_review_count in unique_products.iteritems():\n",
        "    product_reviews = products_df.loc[products_df[\"id\"] == product_id]\n",
        "    product_dfs[product_id] = product_reviews"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        },
        "id": "qFuhF0CgrcVU",
        "outputId": "70433551-dd0e-49fb-f847-4a8b90fea35b"
      },
      "source": [
        "product_dfs[product_least_review]"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>review</th>\n",
              "      <th>rating</th>\n",
              "      <th>title</th>\n",
              "      <th>category</th>\n",
              "      <th>name</th>\n",
              "      <th>review_tokens</th>\n",
              "      <th>token_count</th>\n",
              "      <th>review_tokens_cleaned</th>\n",
              "      <th>review_cleaned</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>941</th>\n",
              "      <td>AV-XeQLWuC1rwyj_gbP5</td>\n",
              "      <td>A lazy mans drean when it is combined with Ale...</td>\n",
              "      <td>5</td>\n",
              "      <td>Awesome!</td>\n",
              "      <td>Electronics</td>\n",
              "      <td>Amazon Fire TV with 4K Ultra HD and Alexa Voic...</td>\n",
              "      <td>[a, lazy, mans, drean, when, it, is, combined,...</td>\n",
              "      <td>23</td>\n",
              "      <td>[lazy, man, drean, combined, alexa, get, harmo...</td>\n",
              "      <td>lazy man drean combined alexa get harmony hub ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>942</th>\n",
              "      <td>AV-XeQLWuC1rwyj_gbP5</td>\n",
              "      <td>I really enjoy my Fire stick. It's really easy...</td>\n",
              "      <td>5</td>\n",
              "      <td>This is a great piece of equipment</td>\n",
              "      <td>Electronics</td>\n",
              "      <td>Amazon Fire TV with 4K Ultra HD and Alexa Voic...</td>\n",
              "      <td>[i, really, enjoy, my, fire, stick., it's, rea...</td>\n",
              "      <td>11</td>\n",
              "      <td>[really, enjoy, fire, stick, really, easy, use]</td>\n",
              "      <td>really enjoy fire stick really easy use</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>943</th>\n",
              "      <td>AV-XeQLWuC1rwyj_gbP5</td>\n",
              "      <td>Really cool device! Instantly noticed the diff...</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Electronics</td>\n",
              "      <td>Amazon Fire TV with 4K Ultra HD and Alexa Voic...</td>\n",
              "      <td>[really, cool, device!, instantly, noticed, th...</td>\n",
              "      <td>23</td>\n",
              "      <td>[really, cool, device, instantly, noticed, dif...</td>\n",
              "      <td>really cool device instantly noticed differenc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>944</th>\n",
              "      <td>AV-XeQLWuC1rwyj_gbP5</td>\n",
              "      <td>Love it! Works great. One in each of the main ...</td>\n",
              "      <td>5</td>\n",
              "      <td>love it!</td>\n",
              "      <td>Electronics</td>\n",
              "      <td>Amazon Fire TV with 4K Ultra HD and Alexa Voic...</td>\n",
              "      <td>[love, it!, works, great., one, in, each, of, ...</td>\n",
              "      <td>11</td>\n",
              "      <td>[love, work, great, one, main, room]</td>\n",
              "      <td>love work great one main room</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       id  ...                                     review_cleaned\n",
              "941  AV-XeQLWuC1rwyj_gbP5  ...  lazy man drean combined alexa get harmony hub ...\n",
              "942  AV-XeQLWuC1rwyj_gbP5  ...            really enjoy fire stick really easy use\n",
              "943  AV-XeQLWuC1rwyj_gbP5  ...  really cool device instantly noticed differenc...\n",
              "944  AV-XeQLWuC1rwyj_gbP5  ...                      love work great one main room\n",
              "\n",
              "[4 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3mGajTdUYdm"
      },
      "source": [
        "One of the simplest approach to extract keywords is to get frequent n-grams. Let us see top n-grams from both raw and clean texts. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8-9XoKjGsNy"
      },
      "source": [
        "def get_ngrams(txt:List[list]):\n",
        "    tokens_unique = []\n",
        "    for tokens in txt:\n",
        "        tokens_unique.extend(tokens)\n",
        "    return tokens_unique"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CR2HiJQ5EVV1",
        "outputId": "5a9dd52a-007d-468e-aa53-90690e7c33e9"
      },
      "source": [
        "product_ngrams = get_ngrams(product_dfs[product_least_review]['review_tokens'])\n",
        "(pd.Series(nltk.ngrams(product_ngrams, 3)).value_counts())[:5]"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(compared, to, the)                 3\n",
              "(i, like, the)                      3\n",
              "(paperwhite,, especially, since)    2\n",
              "(my, paperwhite, to)                2\n",
              "(it, is, to)                        2\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxKmK7TuUYWi",
        "outputId": "89c6bd50-5f67-4591-8566-0f3b3e3c574b"
      },
      "source": [
        "product_ngrams_cleaned = get_ngrams(product_dfs[product_least_review]['review_tokens_cleaned'])\n",
        "(pd.Series(nltk.ngrams(product_ngrams_cleaned, 3)).value_counts())[:5]"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(friend, bought, voyage)      2\n",
              "(extra, cost, compared)       2\n",
              "(gave, paperwhite, friend)    2\n",
              "(easy, turn, page)            2\n",
              "(know, really, worth)         2\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5TefXaoVV1r"
      },
      "source": [
        "## Off-The-Shelf Libraries\n",
        "We'll use some of the unsupervised keyphrase extraction libraries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXz28NK5E_5r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ceac3e43-c481-40bf-af39-d89bcf6718f6"
      },
      "source": [
        "!pip install yake"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting yake\n",
            "  Downloading yake-0.4.8-py2.py3-none-any.whl (60 kB)\n",
            "\u001b[?25l\r\u001b[K     |█████▌                          | 10 kB 20.1 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 20 kB 26.9 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 30 kB 32.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 40 kB 35.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 51 kB 36.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 60 kB 6.5 MB/s \n",
            "\u001b[?25hCollecting jellyfish\n",
            "  Downloading jellyfish-0.8.9.tar.gz (137 kB)\n",
            "\u001b[K     |████████████████████████████████| 137 kB 66.2 MB/s \n",
            "\u001b[?25hCollecting segtok\n",
            "  Downloading segtok-1.5.10.tar.gz (25 kB)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from yake) (0.8.9)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from yake) (2.6.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from yake) (1.18.5)\n",
            "Requirement already satisfied: click>=6.0 in /usr/local/lib/python3.7/dist-packages (from yake) (7.1.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from segtok->yake) (2021.11.10)\n",
            "Building wheels for collected packages: jellyfish, segtok\n",
            "  Building wheel for jellyfish (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jellyfish: filename=jellyfish-0.8.9-cp37-cp37m-linux_x86_64.whl size=73236 sha256=cdb32b12766fa9c6a098e44bf59a6701bb28b3dfd92534c8eba693eff1fd4884\n",
            "  Stored in directory: /root/.cache/pip/wheels/32/a9/ef/5d8742e72deaf0d1de327a180d008c2c0299367581800ea73f\n",
            "  Building wheel for segtok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for segtok: filename=segtok-1.5.10-py3-none-any.whl size=25030 sha256=2a7ea4a08e8f5e6fa22d813d775b0ffd7a483397ef9ff0befe52ff6f9d4b6570\n",
            "  Stored in directory: /root/.cache/pip/wheels/67/b7/d0/a121106e61339eee5ed083bc230b1c8dc422c49a5a28c2addd\n",
            "Successfully built jellyfish segtok\n",
            "Installing collected packages: segtok, jellyfish, yake\n",
            "Successfully installed jellyfish-0.8.9 segtok-1.5.10 yake-0.4.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoK6FRWVEWlK"
      },
      "source": [
        "import yake"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C39g2wihua44"
      },
      "source": [
        "**Setting up hyperparameters**\n",
        "\n",
        "YAKE library offers some option to customize our requirements. They are explained below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oF9TVHf0E9la"
      },
      "source": [
        "language = \"en\" ## Language code should match input text language\n",
        "max_ngram_size = 6 ## Maximum number of tokens in each keyword\n",
        "deduplication_threshold = 0.5 ## Limits the duplication of words in different keywords\n",
        "numOfKeywords = 5  ## Maximum number of keywords to generate\n",
        "deduplication_algo = 'seqm' ## Choices: leve|jaro|seqm\n",
        "windowSize = 5\n",
        "\n",
        "yake_kw_extractor = yake.KeywordExtractor(lan=language, n=max_ngram_size,\n",
        "                                          dedupLim=deduplication_threshold, \n",
        "                                          top=numOfKeywords, windowsSize=windowSize, \n",
        "                                          dedupFunc=deduplication_algo, features=None)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYm1ki9IV6Og"
      },
      "source": [
        "We set higher `windowSize` to extract keywords with more contexts. Additionally, a high `max_ngram_size` also ensures specific keywords.\n",
        "\n",
        "`deduplication_threshold` ensures similar phrases are avoided."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eD5V1T34RHc0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d07dba6-b24f-48f1-a94c-cdb8bb85972e"
      },
      "source": [
        "idx = 5\n",
        "print(product_dfs[product_least_review]['review'].iloc[idx])\n",
        "yake_kw_extractor.extract_keywords(product_dfs[product_least_review]['review'].iloc[idx])"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is a great reader, it feels like the best evolution of the Paperwhite. The auto-brightness works fine and is unnoticeable and it feels good in the hands. The new page squeeze feature is nice as is the haptic feedback when you squeeze the bezel.The power button is also much better placed now and the glass screen makes swiping and tapping the bookmark and location corner areas much easier. The backlight is now much more uniform than my 1st gen Paperwhite.The only issue I have is when displaying black blocks like the tree silhouette, I have what looks like a tiny bad pixel that kind of twinkles. And of course, this thing is expensive when compared to the Paperwhite.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('evolution of the Paperwhite', -0.7238351879001719),\n",
              " ('feels like the best evolution', -0.18439937611624463),\n",
              " ('feature is nice', 0.0),\n",
              " ('swiping and tapping', 0.0),\n",
              " ('glass screen makes swiping and tapping', 0.0)]"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URhxN2lIHnnD"
      },
      "source": [
        "def extract_keywords_yake(txt:str):\n",
        "    keywords = []\n",
        "    keyword_tuples = yake_kw_extractor.extract_keywords(txt)\n",
        "    ## Process extracted keywords: (Lower score has higher relevance)\n",
        "    for kw in keyword_tuples:\n",
        "        keywords.append(kw[0])\n",
        "\n",
        "    return keywords"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QATbr5yHVxtv"
      },
      "source": [
        "We will estimate time requirement for each library as that could be one of the important considerations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LU26XN_oEQhM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e77500ad-b558-4987-8370-15b4152edd23"
      },
      "source": [
        "%%timeit\n",
        "extract_keywords_yake(product_dfs[product_least_review]['review'].iloc[idx])"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 loops, best of 5: 52.2 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGU26zbjIYRO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "418a165b-2ed9-4ba5-a048-78600d9a83e3"
      },
      "source": [
        "extract_keywords_yake(product_dfs[product_least_review]['review'].iloc[idx])"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['evolution of the Paperwhite',\n",
              " 'feels like the best evolution',\n",
              " 'feature is nice',\n",
              " 'swiping and tapping',\n",
              " 'glass screen makes swiping and tapping']"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_pYr8bOvn9d",
        "outputId": "3cb4a96b-0575-4ecd-a177-b8652b940024"
      },
      "source": [
        "!pip install rake_nltk"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rake_nltk in /usr/local/lib/python3.7/dist-packages (1.0.6)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.6.2 in /usr/local/lib/python3.7/dist-packages (from rake_nltk) (3.6.5)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk<4.0.0,>=3.6.2->rake_nltk) (2021.11.10)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk<4.0.0,>=3.6.2->rake_nltk) (4.62.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk<4.0.0,>=3.6.2->rake_nltk) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk<4.0.0,>=3.6.2->rake_nltk) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kffSSwE-T1ab"
      },
      "source": [
        "from rake_nltk import Rake\n",
        "rake_nltk_var = Rake()"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aow2E6_jqxgc"
      },
      "source": [
        "def extract_keywords_rake(txt:str):\n",
        "    rake_nltk_var.extract_keywords_from_text(txt)\n",
        "    keywords = rake_nltk_var.get_ranked_phrases()\n",
        "\n",
        "    return keywords"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwkNsAWuEHI1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de3e453f-0a7c-4dc3-d33d-7dcec570c521"
      },
      "source": [
        "%%timeit\n",
        "extract_keywords_rake(product_dfs[product_least_review]['review'].iloc[idx])"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The slowest run took 85.44 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "10000 loops, best of 5: 175 µs per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b51MKucMIPwZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c9194ab-00cc-422d-cbaa-2d5bb0991002"
      },
      "source": [
        "extract_keywords_rake(product_dfs[product_least_review]['review'].iloc[idx]) [:5]"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['location corner areas much easier',\n",
              " 'glass screen makes swiping',\n",
              " 'also much better placed',\n",
              " 'displaying black blocks like',\n",
              " 'new page squeeze feature']"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6s0BWyUUPHq"
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efccebgJq_9m"
      },
      "source": [
        "def extract_keywords_spacy(txt:str):\n",
        "    doc = nlp(txt)\n",
        "    # print(doc.ents)\n",
        "\n",
        "    return doc.ents"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OO0sm4NkEWXh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76fcb689-5999-40ba-8982-250cfbe67eeb"
      },
      "source": [
        "%%timeit\n",
        "extract_keywords_spacy(product_dfs[product_least_review]['review'].iloc[idx]) ## We are ignoring the time taken in loading the spacy model."
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 loops, best of 5: 22.3 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jek12sltIK6P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86b9c845-b084-4529-8391-d2683c4ebbb1"
      },
      "source": [
        "extract_keywords_spacy(product_dfs[product_least_review]['review'].iloc[idx])"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Paperwhite, 1st, Paperwhite)"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzaHWDTfXBbh"
      },
      "source": [
        "So far we have explored co-occurrence based approaches, let us look into one Deep Extractive approach based on BERT. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9CSoMoto33f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c7c4dd02-e467-40b3-99ca-f066a715ab6a"
      },
      "source": [
        "!pip install keybert ## https://pypi.org/project/keybert/"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keybert\n",
            "  Using cached keybert-0.5.0.tar.gz (19 kB)\n",
            "Collecting sentence-transformers>=0.3.8\n",
            "  Using cached sentence-transformers-2.1.0.tar.gz (78 kB)\n",
            "Requirement already satisfied: scikit-learn>=0.22.2 in /usr/local/lib/python3.7/dist-packages (from keybert) (1.0.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.7/dist-packages (from keybert) (1.18.5)\n",
            "Collecting rich>=10.4.0\n",
            "  Using cached rich-10.14.0-py3-none-any.whl (213 kB)\n",
            "Requirement already satisfied: typing-extensions<5.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from rich>=10.4.0->keybert) (3.10.0.2)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from rich>=10.4.0->keybert) (2.6.1)\n",
            "Collecting commonmark<0.10.0,>=0.9.0\n",
            "  Using cached commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
            "Collecting colorama<0.5.0,>=0.4.0\n",
            "  Using cached colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.2->keybert) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.2->keybert) (3.0.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.2->keybert) (1.4.1)\n",
            "Collecting transformers<5.0.0,>=4.6.0\n",
            "  Using cached transformers-4.12.5-py3-none-any.whl (3.1 MB)\n",
            "Collecting tokenizers>=0.10.3\n",
            "  Using cached tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=0.3.8->keybert) (4.62.3)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=0.3.8->keybert) (1.7.0+cpu)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=0.3.8->keybert) (0.11.1+cu111)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=0.3.8->keybert) (3.6.5)\n",
            "Collecting sentencepiece\n",
            "  Using cached sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "Collecting huggingface-hub\n",
            "  Using cached huggingface_hub-0.1.2-py3-none-any.whl (59 kB)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence-transformers>=0.3.8->keybert) (0.6)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence-transformers>=0.3.8->keybert) (0.16.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Using cached PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (4.8.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (2021.11.10)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (3.4.0)\n",
            "Collecting sacremoses\n",
            "  Using cached sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (3.6.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers>=0.3.8->keybert) (7.1.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (1.15.0)\n",
            "Collecting torch>=1.6.0\n",
            "  Downloading torch-1.10.0-cp37-cp37m-manylinux1_x86_64.whl (881.9 MB)\n",
            "\u001b[K     |██████████████████████████████▎ | 834.1 MB 1.3 MB/s eta 0:00:39tcmalloc: large alloc 1147494400 bytes == 0x55fbd39ac000 @  0x7f42923e7615 0x55fb998a94cc 0x55fb9998947a 0x55fb998ac2ed 0x55fb9999de1d 0x55fb9991fe99 0x55fb9991a9ee 0x55fb998adbda 0x55fb9991fd00 0x55fb9991a9ee 0x55fb998adbda 0x55fb9991c737 0x55fb9999ec66 0x55fb9991bdaf 0x55fb9999ec66 0x55fb9991bdaf 0x55fb9999ec66 0x55fb9991bdaf 0x55fb998ae039 0x55fb998f1409 0x55fb998acc52 0x55fb9991fc25 0x55fb9991a9ee 0x55fb998adbda 0x55fb9991c737 0x55fb9991a9ee 0x55fb998adbda 0x55fb9991b915 0x55fb998adafa 0x55fb9991bc0d 0x55fb9991a9ee\n",
            "\u001b[K     |████████████████████████████████| 881.9 MB 16 kB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence-transformers>=0.3.8->keybert) (7.1.2)\n",
            "Building wheels for collected packages: keybert, sentence-transformers\n",
            "  Building wheel for keybert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keybert: filename=keybert-0.5.0-py3-none-any.whl size=20491 sha256=56c9a2dd82309d244061fe5fb47e2fac5a1424daa152e8dc2416a5567e0b068a\n",
            "  Stored in directory: /root/.cache/pip/wheels/99/1f/3f/590d2997adbb2d0e1f82e8ee05d42d6910e92c3ed283015ff8\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.1.0-py3-none-any.whl size=120999 sha256=36b80f2ca572e704fb2e295979b861d2eb2ecff4893d68bd2a9fc2205cf7dc27\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/f0/bb/ed1add84da70092ea526466eadc2bfb197c4bcb8d4fa5f7bad\n",
            "Successfully built keybert sentence-transformers\n",
            "Installing collected packages: pyyaml, torch, tokenizers, sacremoses, huggingface-hub, transformers, sentencepiece, commonmark, colorama, sentence-transformers, rich, keybert\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.7.0+cpu\n",
            "    Uninstalling torch-1.7.0+cpu:\n",
            "      Successfully uninstalled torch-1.7.0+cpu\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "aspectnlp 0.0.4 requires nltk==3.2.5, but you have nltk 3.6.5 which is incompatible.\n",
            "aspectnlp 0.0.4 requires torch==1.7.0+cpu, but you have torch 1.10.0 which is incompatible.\u001b[0m\n",
            "Successfully installed colorama-0.4.4 commonmark-0.9.1 huggingface-hub-0.1.2 keybert-0.5.0 pyyaml-6.0 rich-10.14.0 sacremoses-0.0.46 sentence-transformers-2.1.0 sentencepiece-0.1.96 tokenizers-0.10.3 torch-1.10.0 transformers-4.12.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch",
                  "yaml"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6jGbNwZo6CY"
      },
      "source": [
        "from keybert import KeyBERT\n",
        "\n",
        "kb_model = KeyBERT()"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pC2krqIlrTAg"
      },
      "source": [
        "def extract_keywords_keybert(txt:str, ngrams_min:int=2, ngrams_max:int=4, stop_words=None):\n",
        "    keyword_tuples = kb_model.extract_keywords(txt, keyphrase_ngram_range=(ngrams_min, ngrams_max), stop_words=stop_words)\n",
        "    \n",
        "    keywords = []\n",
        "    ## Process extracted keywords: (Lower score has higher relevance)\n",
        "    for kw in keyword_tuples:\n",
        "        keywords.append(kw[0])\n",
        "    return keywords"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1FOvLupEjpH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4370ae3c-0a0f-4c3b-c5c6-479a21db9b99"
      },
      "source": [
        "%%timeit\n",
        "extract_keywords_keybert(product_dfs[product_least_review]['review'].iloc[idx])"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 loop, best of 5: 1.3 s per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lO4SkQSPXTqE"
      },
      "source": [
        "BERT based approach has significant time and computational requirement over co-occurrence based approaches."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dbf5YwR1H_l3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e463307-742a-4282-e44d-e6c596dd962b"
      },
      "source": [
        "extract_keywords_keybert(product_dfs[product_least_review]['review'].iloc[idx])"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['paperwhite the auto brightness',\n",
              " 'compared to the paperwhite',\n",
              " 'paperwhite the only issue',\n",
              " '1st gen paperwhite',\n",
              " 'the paperwhite']"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDsYcejuXiQE"
      },
      "source": [
        "Let us aggregate over the reviews for each product.\n",
        "We aggregate by considering extracted keyphrases from all reviews and counting their frequency. Finally, take most frequent keyphrases as our answer.\n",
        "\n",
        "However, this approach generates very similar keywords. To counter that we add a simple deduplication based on a similarity score which I have defined below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDZaOeWuys8k"
      },
      "source": [
        "def get_keywords_for_product(df: pd.DataFrame):\n",
        "    keywords = []\n",
        "    for idx, row in df.iterrows():\n",
        "        review = row['review']\n",
        "        kws = extract_keywords_rake(review)\n",
        "        keywords.extend(kws)\n",
        "\n",
        "    return keywords"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQHeURIoXsMG"
      },
      "source": [
        "We define a scorer which takes repeated elements into account. This is inspired from Jaccard Distance. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maWXZefu60Jh"
      },
      "source": [
        "def repeated_sim_score(txt1, txt2):\n",
        "    \"\"\" Calculates similarity score with allowing repeated elements\"\"\"\n",
        "    txt1_split = txt1.split()\n",
        "    txt2_split = txt2.split() \n",
        "    txt1_c = Counter(txt1_split)\n",
        "    txt2_c = Counter(txt2_split)\n",
        "    intersection = (txt1_c - txt2_c) + (txt2_c - txt1_c)\n",
        "    intersection_count = sum(intersection.values())\n",
        "\n",
        "    return (intersection_count/(len(txt1_split) + len(txt2_split) - intersection_count + 1))"
      ],
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcE9-0737pEa",
        "outputId": "10ef8871-f0ac-46af-944c-2bcb5a4400e7"
      },
      "source": [
        "txt1 = 'the paperwhite especially'\n",
        "txt2 = 'the paperwhite especially since'\n",
        "txt2 = 'fire hd'\n",
        "\n",
        "repeated_sim_score(txt1, txt2)"
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({'the': 1, 'paperwhite': 1, 'especially': 1, 'fire': 1, 'hd': 1}) Counter({'the': 1, 'paperwhite': 1, 'especially': 1}) Counter({'fire': 1, 'hd': 1})\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.0"
            ]
          },
          "metadata": {},
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFw6P1Isw36E"
      },
      "source": [
        "def aggregate_keywords(keywords: List, n=5, diversify=True):\n",
        "    keyword_freqs = Counter(keywords)\n",
        "    top_keywords_odict = OrderedDict(keyword_freqs.most_common())\n",
        "    keywords_selected = []\n",
        "    if diversify: ## This is another level of deduplication which works across reviews\n",
        "        for keyword in top_keywords_odict.keys():\n",
        "            if not keywords_selected:\n",
        "                keywords_selected.append(keyword)\n",
        "                continue\n",
        "            elif len(keywords_selected) >= n:\n",
        "                break\n",
        "\n",
        "            similar_flag = False\n",
        "            for already_selected_keyword in keywords_selected:\n",
        "                score = repeated_sim_score(already_selected_keyword, keyword)\n",
        "                if score < 0.5:\n",
        "                    similar_flag = True\n",
        "            \n",
        "            if not similar_flag:\n",
        "                keywords_selected.append(keyword)\n",
        "                similar_flag = False\n",
        "\n",
        "    return keywords_selected"
      ],
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deS2bcdm1Jcw"
      },
      "source": [
        "product_keywords = get_keywords_for_product(product_dfs[product_least_review])\n",
        "# product_keywords"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_CeZhwp1RM9",
        "outputId": "97f3c5db-7c10-41be-eca1-aeb316e1ae2c"
      },
      "source": [
        "final_keywords = aggregate_keywords(product_keywords, n=5)\n",
        "final_keywords"
      ],
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['compared to the paperwhite',\n",
              " 'the paperwhite especially',\n",
              " 'fire hd',\n",
              " 'sunlight other than fire',\n",
              " 'read in the sunlight']"
            ]
          },
          "metadata": {},
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dD3zjyQ6YPU_"
      },
      "source": [
        "Extracting keywords for all products"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPt9fdu-DaU0"
      },
      "source": [
        "def get_keywords_for_all(dfs:Dict, n=5):\n",
        "    final_keywords = {}\n",
        "    for product, df in dfs.items():\n",
        "        product_keywords = get_keywords_for_product(df)\n",
        "        final_keywords[product] = aggregate_keywords(product_keywords, n=n)\n",
        "\n",
        "    return final_keywords"
      ],
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVR8YRZID7Ig"
      },
      "source": [
        "keywords = get_keywords_for_all(product_dfs, n=5)"
      ],
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGLKOQsbNAra",
        "outputId": "1d326195-7998-4991-9ff6-4c65f29ef6c6"
      },
      "source": [
        "for idx, keyword in keywords.items():\n",
        "    print(f'Keywords for Product [{products_df.loc[products_df[\"id\"] == idx][\"name\"].iloc[0]}] are: \\n{keyword}.')"
      ],
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keywords for Product [All-New Fire HD 8 Tablet, 8\" HD Display, Wi-Fi, 16 GB - Includes Special Offers, Magenta] are: \n",
            "['this tablet', 'kindle fire', 'great tablet', 'easy to use', 'good tablet'].\n",
            "Keywords for Product [Amazon Echo Show Alexa-enabled Bluetooth Speaker with 7\" Screen] are: \n",
            "['the echo show', 'amazon echo', 'smart home', 'easy to set up', 'easy to use'].\n",
            "Keywords for Product [Amazon - Echo Plus w/ Built-In Hub - Silver] are: \n",
            "['the echo plus', 'amazon echo', 'easy to set up', 'love alexa', 'smart home'].\n",
            "Keywords for Product [Fire Kids Edition Tablet, 7 Display, Wi-Fi, 16 GB, Blue Kid-Proof Case] are: \n",
            "['this tablet', 'great tablet', 'tablet for kids', 'easy to use', 'parental controls'].\n",
            "Keywords for Product [Brand New Amazon Kindle Fire 16gb 7\" Ips Display Tablet Wifi 16 Gb Blue] are: \n",
            "['this tablet', 'great tablet', 'fire tablet', 'kindle fire', 'easy to use'].\n",
            "Keywords for Product [Fire Tablet, 7 Display, Wi-Fi, 16 GB - Includes Special Offers, Black] are: \n",
            "['this tablet', 'great tablet', 'kindle fire', 'fire tablet', 'easy to use'].\n",
            "Keywords for Product [Amazon Tap - Alexa-Enabled Portable Bluetooth Speaker] are: \n",
            "['amazon tap', 'the echo', 'amazon echo', 'bluetooth speaker', 'the sound is great'].\n",
            "Keywords for Product [Fire Kids Edition Tablet, 7 Display, Wi-Fi, 16 GB, Green Kid-Proof Case] are: \n",
            "['this tablet', 'parental controls', 'tablet for kids', 'kindle fire', 'grandson he loves it'].\n",
            "Keywords for Product [Amazon Echo Show Alexa-enabled Bluetooth Speaker with 7\" Screen] are: \n",
            "['the echo show', 'amazon echo', 'smart home', 'echo show is great', 'easy to set up'].\n",
            "Keywords for Product [Kindle E-reader - White, 6 Glare-Free Touchscreen Display, Wi-Fi - Includes Special Offers] are: \n",
            "['this kindle', 'love my kindle', 'the kindle', 'the paperwhite', 'good product and service'].\n",
            "Keywords for Product [Fire HD 10 Tablet, 10.1 HD Display, Wi-Fi, 16 GB - Includes Special Offers, Silver Aluminum] are: \n",
            "['this tablet', 'kindle fire', 'amazon fire', 'best buy', 'love my new kindle'].\n",
            "Keywords for Product [Fire Tablet with Alexa, 7\" Display, 16 GB, Magenta - with Special Offers] are: \n",
            "['great tablet', 'this tablet', 'my kindle', 'tablet has', 'fire tablet'].\n",
            "Keywords for Product [Amazon Kindle E-Reader 6\" Wifi (8th Generation, 2016)] are: \n",
            "['the kindle', 'kindle is light', 'second kindle', 'amazon kindle', 'love my kindle'].\n",
            "Keywords for Product [Amazon - Kindle Voyage - 6\" - 4GB - Black] are: \n",
            "['new kindle', 'the kindle', 'this kindle', 'best kindle', 'bought this reader'].\n",
            "Keywords for Product [All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi, 32 GB - Includes Special Offers, Blue] are: \n",
            "['this tablet', 'speakers lasted week on', 'will not turn on', 'new kindle fire', 'second kindle'].\n",
            "Keywords for Product [All-New Fire HD 8 Tablet, 8\" HD Display, Wi-Fi, 32 GB - Includes Special Offers, Black] are: \n",
            "['kindle fire hd', 'easy to use', 'perfect tablet for', 'tablet for the avid', 'the amazon fire hd'].\n",
            "Keywords for Product [Fire HD 8 Tablet with Alexa, 8\" HD Display, 32 GB, Tangerine - with Special Offers] are: \n",
            "['this tablet', 'kindle fire', 'new kindle', 'easy to use', 'kindles for'].\n",
            "Keywords for Product [All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi, 16 GB - Includes Special Offers, Blue] are: \n",
            "['this tablet', 'tablet is great', 'solid will update review', 'update review as soon', 'kindle fire'].\n",
            "Keywords for Product [All-New Fire HD 8 Tablet, 8\" HD Display, Wi-Fi, 32 GB - Includes Special Offers, Magenta] are: \n",
            "['this tablet', 'new kindle', 'kindle fire', 'video quality is very', 'kindles but this new'].\n",
            "Keywords for Product [Kindle Oasis E-reader with Leather Charging Cover - Black, 6\" High-Resolution Display (300 ppi), Wi-Fi - Includes Special Offers] are: \n",
            "['lightweight and convenient to', 'love my new kindle', 'wife love it reads', 'it reads lot and', 'kindle since the'].\n",
            "Keywords for Product [Kindle Oasis E-reader with Leather Charging Cover - Merlot, 6 High-Resolution Display (300 ppi), Wi-Fi - Includes Special Offers] are: \n",
            "['kindle oasis remains comfortable', 'äôm doing the kindle', 'kindle oasis wakes', 'while read sometimes äôm', 'kindle paperwhite and voyage'].\n",
            "Keywords for Product [Amazon 9W PowerFast Official OEM USB Charger and Power Adapter for Fire Tablets and Kindle eReaders] are: \n",
            "['kindle charger', 'needed second charger for', 'it charges my kindle', 'my daughter lost kindle', 'alternative products'].\n",
            "Keywords for Product [Amazon - Kindle Voyage - 4GB - Wi-Fi + 3G - Black] are: \n",
            "['compared to the paperwhite', 'the paperwhite especially', 'fire hd', 'sunlight other than fire', 'read in the sunlight'].\n",
            "Keywords for Product [Amazon Fire TV with 4K Ultra HD and Alexa Voice Remote (Pendant Design) | Streaming Media Player] are: \n",
            "['the harmony hub', 'combined with alexa', 'enjoy my fire stick', 'fire stick it really', 'fire tv with 4k'].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOHu6eoqP2oL"
      },
      "source": [
        "#### Qualitative Investigation\n",
        "We saw 4 approaches here, let us manually investigate the quality of keyphrases extracted by each apporach."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFJQevMksZ1J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2218c356-7f72-46d7-eab7-58b98a6caf95"
      },
      "source": [
        "def process_texts(df: pd.DataFrame):\n",
        "    yake_keywords_set = set()\n",
        "    rake_keywords_set = set()\n",
        "    spacy_keywords_set = set()\n",
        "    keybert_keywords_set = set()\n",
        "    review_wise_keywords = []\n",
        "    for idx, row in df.iterrows():\n",
        "        review = row['review']\n",
        "        yake_kws = extract_keywords_yake(review)\n",
        "        # print(yake_kws)\n",
        "        rake_kws = extract_keywords_rake(review)\n",
        "        # print(rake_kws)\n",
        "        spacy_kws = extract_keywords_spacy(review)\n",
        "        # print(spacy_kws)\n",
        "        keybert_kws = extract_keywords_keybert(review)\n",
        "        # print(keybert_kws)\n",
        "        yake_keywords_set.update(yake_kws)\n",
        "        rake_keywords_set.update(rake_kws)\n",
        "        spacy_keywords_set.update(spacy_kws)\n",
        "        keybert_keywords_set.update(keybert_kws)\n",
        "        # review_wise_keywords[idx] = kws\n",
        "\n",
        "    return yake_keywords_set, rake_keywords_set, spacy_keywords_set, keybert_keywords_set\n",
        "\n",
        "yake_keywords_set, rake_keywords_set, spacy_keywords_set, keybert_keywords_set = \\\n",
        "    process_texts(product_dfs[product_least_review])\n",
        "print(yake_keywords_set)\n",
        "print(rake_keywords_set)\n",
        "print(spacy_keywords_set)\n",
        "print(keybert_keywords_set)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Love', 'expensive', 'Love Love', 'huge', 'huge selection of books', 'Fast', 'side pressure page advance', 'connected to WIFI to download books', 'read in the sunlight', 'high class e reader', 'good battery life', 'Enjoy my summer reading', 'good', 'easy', 'unnecessary now I am wishing', 'great back lighting', 'high', 'friend and bought the Voyage', 'selection', 'product', 'big tech heaven in the sky', 'easier to read in all lightings', 'needed', 'works great', 'Kindle and cover were a gift', 'small size fits my small hands', 'Voyage', 'backlit so needed', 'wife', 'easier to read', 'complaints works great and the battery', 'solid', 'daughter', 'Love the new Voyage', 'wishing I had purchased', 'gift for my wife', 'fantastic product', 'back light nad easier to read', 'Kindle', 'handle', 'happy and satisfiedEasier to handle', 'reading books', 'Kindle Voyage', 'summer reading and a regular tablet', 'absolutely loves', 'heard', 'e-reader', 'needed something to read', 'happy', 'evolution of the Paperwhite', 'sunlight other than fire', 'love', 'WIFI to download', 'Purchased it for my daughter', 'clearness of the screen', 'version es too expensive', 'nad easier', 'glass screen makes swiping and tapping', 'great and the battery is awesome', 'purchase this for my wife', 'love this e-reader', 'connected to WIFI', 'feels like the best evolution', 'works', 'reader', 'boyfriend', 'Great', 'beats', 'Purchased', 'difference is a light', 'Fast charging', 'feature is nice', 'class', 'hrs daily', 'Voyage bc it is lighter', 'Easy', 'fantastic product for reading books', 'generation Kindle', 'light', 'light to read', 'lighter and smaller', 'product for my boyfriend', 'wanted this when I first heard', 'satisfiedEasier', 'Paperwhite to a friend and bought', 'wanted', 'books', 'gave my Paperwhite to a friend', 'back light nad', 'Easier to tuck in my purse', 'complaints works', 'generation Kindle because I wanted', 'time for reading', 'Pricey', 'life', 'read', 'swiping and tapping', 'library', 'features for an ebook'}\n",
            "{'expensive', 'small size', 'compared', 'nice', 'think', 'side pressure page advance', 'small', 'thing', 'feels good', 'great reader', 'affected', 'screen', 'best evolution', 'portability', 'smaller', 'really worth', 'power button', 'initially disappointed', 'quickly learned', 'high class e reader', 'good battery life', 'sooner', 'thought', 'tiny bad pixel', 'bezel', 'like', 'issue', 'easy', 'expect', 'unnecessary', 'great back lighting', 'love downloading books', 'serious readers', 'completly worth', 'nothing beats', 'download books', '300 dpi', 'lost', 'product', '3g capability', 'believe', 'portable', 'plus', 'hands', 'cover', 'seek', 'complaints works great', 'polarized sunglasses ... great battery life ... great build quality ...', 'happier', 'love love', 'wanted something easy', 'satisfiedeasier', 'fan', 'tuck', '1st generation kindle', 'gave', 'brightness works fine', 'products', 'husband surprised', 'kindle fire', 'enjoy', 'adjustable', 'new one', 'traveling 4 days plus per week nothing beats', 'wife', 'easier', 'battery', 'solid', 'lighter', 'kind', 'daughter', 'small hands', 'extra cost compared', 'would', 'uses', 'small size fits', 'upgraded', 'much', 'voyage', 'lightweight', 'fantastic product', 'last kindle', 'also much better placed', 'tree silhouette', 'version es', 'lightings', 'real book experience', 'big tech heaven', 'go', 'appreciate', 'gift', 'best gift', 'could use', 'new page squeeze feature', 'sun', 'summer reading', 'kindle', 'fast charging', 'handle', 'bit', 'really good', 'reading books', 'uniform', 'absolutely loves', 'train', 'unnoticeable', 'last', 'eyes', 'happy', 'love', 'tapping', 'yes ...', 'turn pages', 'glass screen makes swiping', 'way', 'library e', 'purchase', 'replace', 'low light', 'ebook', 'noticeable improvement', 'twinkles', 'compact model', 'back light nad easier', 'came', 'awesome', 'looks like', 'needed something', 'time', '1st gen paperwhite', 'ability', 'definitely', 'held', 'purse', 'wifi', 'new voyage bc', 'difference', 'much longer battery life', 'fire hd', 'cool', 'wi', 'wishing', 'auto light feature', '3g connection', 'backlight ), exceptional direct sun readability', 'especially since', 'auto', 'use', 'fast', 'reader', 'users', 'used yet', 'boyfriend', 'sunlight', '3 hrs daily', 'much better', 'purchased', 'location corner areas much easier', 'add', 'work well', 'reading', 'feel', 'full sunshine', 'backlight', 'recomend', 'light', 'connected', 'fi areas', 'birthday', 'bought', 'pay', 'e', 'wanted', 'friend', 'get good use', 'bookmark', 'books', 'clearness', 'kindle voyage', 'convenient', 'pricey', 'amazon', 'one offers', 'far used', 'course', 'always', 'backlit', 'works perfectly', 'huge selection', 'least 2', 'wonderful', 'full sunlight make', 'necessary features', 'got', 'previous one went', 'fly ... never', 'know', 'squeeze', 'read', 'first heard', 'library', 'sky', 'night', 'displaying black blocks like', 'loves', 'regular tablet', 'long time ...', 'feels like', 'haptic feedback', 'paperwhite'}\n",
            "{daily, Kindle, Voyage, The Kindle Voyage, Paperwhite, 3, Paperwhite, Paperwhite, 3, Amazon, summer, one, 300 dpi, at least 2-3, one, WIFI, 1st, first, 4 days plus, 3, at night, one, 1st, 300 dpi, Paperwhite, Voyage}\n",
            "{'satisfiedeasier to handle fast', 'other than fire hd', 'kindle and cover', 'ebook like the', 'lightweight it was very', 'the battery is awesome', 'the kindle and cover', 'happy and satisfiedeasier to', 'small and lightweight it', 'good battery life great', 'books completly worth', 'read in the sunlight', 'good battery life', 'the paperwhite especially', 'the kindle voyage is', 'use in low light', 'ebook like the side', 'daughter she love this', 'great back lighting', 'the best gift', 'library books completly worth', 'of books recomend it', 'too expensive the difference', 'regular tablet just', 'compared to the paperwhite', 'wife it work well', 'above high class reader', 'expensive the difference is', 'selection of books recomend', 'complaints works great', 'full sunshine have kindle', 'ebook like', 'lightweight it', '1st generation kindle', 'users of library books', 'kindle fire', 'kindle voyage is definitely', 'paperwhite the only issue', 'the best gift love', 'easy to use', 'to handle fast charging', 'generation kindle', 'small and lightweight', 'no complaints works great', 'the kindle and', 'book experience traveling', 'purchased it', 'best gift', 'happy and satisfiedeasier', 'wifi to download books', 'reader was not backlit', 'easy to use good', 'the new voyage', 'kindle voyage is', 'it is really good', 'sunlight other than fire', 'gift love love it', 'very happy and satisfiedeasier', 'back light nad easier', 'reading at night', 'reading and regular tablet', 'the paperwhite especially since', '1st gen paperwhite', 'tablet just', 'kindle and cover were', 'of books recomend', 'it for my daughter', 'fire hd', 'paperwhite especially since the', 'love the new voyage', 'than fire hd', 'new voyage', 'sunshine have kindle fire', 'the kindle fire', 'the back light nad', 'kindle fire so', 'reader love it use', 'back light', 'the paperwhite', 'no complaints works', 'how small and lightweight', 'books completly worth it', 'wife it work', 'my wife it work', 'was the best gift', 'read in all lightings', 'for reading at night', 'selection of books', 'new voyage bc it', 'purchased it for my', 'class reader love it', 'paperwhite the auto brightness', 'books recomend it', 'lighter and smaller easier', 'complaints works great and', 'an ebook', 'reading at night and', 'high class reader', 'the kindle', 'high class reader love', 'regular tablet', 'features for an ebook', 'the back light'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpXUdBb7YwY3"
      },
      "source": [
        "* **YAKE**: Generates mix of single and multi word keyphrases. Single word phrases can be removed easily. YAKE is able to extract useful keyphrases such as 'good battery life'. However, it takes 52ms per example.\n",
        "* **RAKE**: Is the fastest, but it might be caching the result. Is able to extract useful keyphrase such as 'initially disappointed' or 'quickly learned'\n",
        "* **Spacy**: Extracts single word keyphrases (e.g. Kindle) and it does not provide any option to customized either. However, it is one of the fastest running option.\n",
        "* **KeyBERT**: is able to extract meaningful keyphrases such as 'lightweight it was very' or 'the battery is awesome'. However, it is the slowest, taking 1+ sec per example. Knowledge Distillation may be applied for faster response. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lXkmCzTAZKk"
      },
      "source": [
        "## Future Directions\n",
        "\n",
        "Although we saw a few approaches along with their advantage and demerits, there are various approaches which can be employed to enrich the understanding. One such possibility is Aspect-based Sentiment Analysis (ABSA). ABSA tries to understand the sentiment of a text given the aspect. For example, in a review about restaurant, a user can be happy about food taste but can have negative  about service.\n",
        "\n",
        "If we analyse the sentiment of the user with respect to each extracted keyphrase and color code using aggregated sentiment, that will add more value. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TJ5sbmHRbcn"
      },
      "source": [
        "**Given sufficient time and resources I would go with below approach:** \n",
        "\n",
        "1.   Train a model with language modelling task using our unsupervised products data \n",
        "2.   Calculate perplexity over any keyphrase extraction datasets [1] to get most similar examples from multiple datasets\n",
        "3.   Consider the examples with lowest perplexity scores along with their labels, these can be used as seed data for our model (seed_data_1)\n",
        "4.   Assign labels by myself to few (approx 100) examples (seed_data_2)\n",
        "5.   Use a portion (60%) of the seed_data_2 for evaluation \n",
        "6.   Mix rest 40% of seed_data_2 with seed_data_1\n",
        "7.   Retrain the initial model for KeyPhrase Extraction with additional extraction head\n",
        "8.   Iterate multiple times following above mentioned process.\n",
        "9.   Additional: Use different weights for loss calculation for seed_data_1 and seed_data_2 during training\n",
        "\n",
        "[1] Key Phrase Extraction Datasets: https://github.com/boudinfl/ake-datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klNEMiQEUl6j"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
